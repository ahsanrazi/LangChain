{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9zHYXzLl+mXdv4xbwaNxH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahsanrazi/LangChain/blob/main/08_RAG_APP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval Augmented Generation (RAG) App"
      ],
      "metadata": {
        "id": "gulvonQTM78d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY').strip()"
      ],
      "metadata": {
        "id": "icF2AVQyRuFj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_6o0Y5GGiXz",
        "outputId": "7db0b8ad-9286-42ab-b108-7f9889ff5ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.7/148.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langgraph\n",
        "!pip install -qU langchain-text-splitters\n",
        "!pip install -qU langchain-community\n",
        "!pip install -qU langchain-google-genai\n",
        "!pip install -qU langchain-pinecone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One of the most powerful applications enabled by LLMs is sophisticated question-answering (Q&A) chatbots.\n",
        "# These are applications that can answer questions about specific source information.\n",
        "# These applications use a technique known as Retrieval Augmented Generation, or RAG."
      ],
      "metadata": {
        "id": "maBikYiYNAoE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview"
      ],
      "metadata": {
        "id": "Y6NOKKGcNquj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A typical RAG application has two main components\n",
        "\n",
        "# A typical RAG application has two main components:\n",
        "# Indexing: a pipeline for ingesting data from a source and indexing it. This usually happens offline.\n",
        "# Retrieval and generation: The actual RAG chain, which takes the user query at run time and retrieves the relevant data from the index,\n",
        "# then passes that to the model."
      ],
      "metadata": {
        "id": "EuxljaOjNrUx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Indexing"
      ],
      "metadata": {
        "id": "BFwKBQ5_QCEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load: First we need to load our data. This is done with Document Loaders.\n",
        "\n",
        "# Split: Text splitters break large Documents into smaller chunks. This is useful both for indexing data and passing it into a model,\n",
        "# as large chunks are harder to search over and won't fit in a model's finite context window.\n",
        "\n",
        "# Embed-Store: We need somewhere to store and index our splits, so that they can be searched over later.\n",
        "# This is often done using a VectorStore and Embeddings model."
      ],
      "metadata": {
        "id": "l03QyPuAQBUt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval and generation"
      ],
      "metadata": {
        "id": "HvihUIsmQkr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve: Given a user input, relevant splits are retrieved from storage using a Retriever.\n",
        "# Generate: A ChatModel / LLM produces an answer using a prompt that includes both the question with the retrieved data."
      ],
      "metadata": {
        "id": "n5r2kNV3QlYI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat Model"
      ],
      "metadata": {
        "id": "UZSCFC2hShgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash-exp\", api_key=gemini_api_key)"
      ],
      "metadata": {
        "id": "_hetk3l4SjQn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding Model"
      ],
      "metadata": {
        "id": "C4oQp80IS8HV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key = gemini_api_key)"
      ],
      "metadata": {
        "id": "agNyDlI0S5PQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectore Store"
      ],
      "metadata": {
        "id": "4MWAdNdjYQXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "\n",
        "index_name = \"langchain\"\n",
        "namespace = \"RAG\"\n",
        "\n",
        "pc = Pinecone(api_key= userdata.get('PINECONE_API'))\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "vector_store = PineconeVectorStore(embedding=embeddings, index=index, namespace=namespace)"
      ],
      "metadata": {
        "id": "4kY60LV6YcNo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Indexing"
      ],
      "metadata": {
        "id": "ip6oeNbaVUns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading documents"
      ],
      "metadata": {
        "id": "NaIyXJwZVZGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to first load the blog post contents. We can use DocumentLoaders for this, which are objects\n",
        "# that load in data from a source and return a list of Document objects.\n",
        "\n",
        "# In this case we’ll use the WebBaseLoader, which uses urllib to load HTML from web URLs and BeautifulSoup to parse it to text."
      ],
      "metadata": {
        "id": "NDsTH_u4Vaqp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# Only keep post title, headers, and content from the full HTML.\n",
        "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
        "loader = WebBaseLoader(web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",), bs_kwargs={\"parse_only\": bs4_strainer})\n",
        "docs = loader.load()\n",
        "\n",
        "assert len(docs) == 1\n",
        "print(f\"Total characters: {len(docs[0].page_content)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41zU92GoWAaB",
        "outputId": "50faf98f-855f-45f7-8c5f-ccadf869b3bd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total characters: 43130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB3ADuXpWnku",
        "outputId": "fcf915bd-e0f0-4e16-ac5d-78070663faf8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "      LLM Powered Autonomous Agents\n",
            "    \n",
            "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
            "\n",
            "\n",
            "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
            "Agent System Overview#\n",
            "In\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting documents"
      ],
      "metadata": {
        "id": "R8J0c5r7Xo24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Our loaded document is over 42k characters which is too long to fit into the context window of many models.\n",
        "# Even for those models that could fit the full post in their context window, models can struggle to find information in very long inputs.\n",
        "\n",
        "# To handle this we’ll split the Document into chunks for embedding and vector storage.\n",
        "# This should help us retrieve only the most relevant parts of the blog post at run time.\n",
        "\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,  # chunk size (characters)\n",
        "    chunk_overlap=200,  # chunk overlap (characters)\n",
        "    add_start_index=True,  # track index in original document\n",
        ")\n",
        "all_splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "SbzpcwlTXdhH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8AClYVESgi-",
        "outputId": "aad7790f-4db0-4e9b-c625-2243d7d7ea7d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split blog post into 66 sub-documents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Storing documents"
      ],
      "metadata": {
        "id": "1JkQepUtTBrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we need to index our 66 text chunks so that we can search over them at runtime.\n",
        "\n",
        "document_ids = vector_store.add_documents(documents=all_splits)"
      ],
      "metadata": {
        "id": "RsRHzfS0SjOd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(document_ids[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWdRnDM0S_23",
        "outputId": "5e1a107e-b1d3-4834-8d73-4c3ee0c3a48b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['066eb41d-db91-40b3-8ccb-e7f175c4c1f8', '1c813cc2-679b-4d91-b760-514302575a8c', '1b11d3a8-ac8f-4ffd-b46b-5b5444bd77ee']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Retrieval and Generation"
      ],
      "metadata": {
        "id": "3aIIFQFPTuz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let’s write the actual application logic. We want to create a simple application that takes a user question, searches for documents\n",
        "# relevant to that question, passes the retrieved documents and initial question to a model, and returns an answer.\n",
        "\n",
        "# For generation, we will use the chat model\n",
        "# We’ll use a prompt for RAG\n",
        "\n",
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "example_messages = prompt.invoke({\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}).to_messages()\n",
        "\n",
        "assert len(example_messages) == 1\n",
        "print(example_messages[0].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJSP6kQHThOh",
        "outputId": "6a411bb5-2cd9-4f80-b576-b7f4b3c8fd2c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: (question goes here) \n",
            "Context: (context goes here) \n",
            "Answer:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll use LangGraph to tie together the retrieval and generation steps into a single application.\n",
        "\n",
        "# This will bring a number of benefits:\n",
        "# We can define our application logic once and automatically support multiple invocation modes, including streaming, async, and batched calls.\n",
        "# We can easily add key features to our application, including persistence and human-in-the-loop approval, with minimal code changes."
      ],
      "metadata": {
        "id": "LUaQZEqfVw1M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To use LangGraph, we need to define three things:\n",
        "\n",
        "# The state of our application;\n",
        "# The nodes of our application (i.e., application steps);\n",
        "# The \"control flow\" of our application (e.g., the ordering of the steps)."
      ],
      "metadata": {
        "id": "6GLdhkn-WyWW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### State"
      ],
      "metadata": {
        "id": "F-FVG3tEW1x0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The state of our application controls what data is input to the application, transferred between steps, and output by the application.\n",
        "# It is typically a TypedDict, but can also be a Pydantic BaseModel.\n",
        "\n",
        "# For a simple RAG application, we can just keep track of the input question, retrieved context, and generated answer:\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from typing_extensions import List, TypedDict\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str"
      ],
      "metadata": {
        "id": "4EGoFfxSW050"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Nodes (application steps)"
      ],
      "metadata": {
        "id": "SiQEnJ4HXSZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's start with a simple sequence of two steps: retrieval and generation\n",
        "\n",
        "def retrieve(state: State):\n",
        "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
        "    return {\"context\": retrieved_docs}\n",
        "\n",
        "\n",
        "def generate(state: State):\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"answer\": response.content}"
      ],
      "metadata": {
        "id": "cRxA1FDYXOwU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Control flow"
      ],
      "metadata": {
        "id": "lbO_rex9Ygc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we compile our application into a single graph object. In this case, we are just connecting the retrieval and generation steps into a single sequence.\n",
        "\n",
        "from langgraph.graph import START, StateGraph\n",
        "\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "ddOf6KQ0YaxM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LangGraph also comes with built-in utilities for visualizing the control flow of your application:\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "GTADl8L1Y9ls",
        "outputId": "fe197236-a71e-440f-cd39-6f5b5842384c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usage"
      ],
      "metadata": {
        "id": "kcGfKSiXaKlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke:\n",
        "\n",
        "result = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
        "\n",
        "print(f'Context: {result[\"context\"]}\\n\\n')\n",
        "print(f'Answer: {result[\"answer\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACu0tV91aHrT",
        "outputId": "a516627d-8b1e-4b05-f165-7ea047087a1a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: [Document(id='1b11d3a8-ac8f-4ffd-b46b-5b5444bd77ee', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585.0}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='7111d4a4-51bd-49c9-96a7-a72b14f5b784', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192.0}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='78ad26c4-4734-45a1-bda0-a06857e6084a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17413.0}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'), Document(id='4cc1ae5a-7b63-4a8c-92fb-b0a170b5cc1a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 19372.0}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\")]\n",
            "\n",
            "\n",
            "Answer: Task decomposition involves breaking down a complex task into smaller, more manageable steps. This can be achieved through prompting an LLM, using task-specific instructions, or with human input. Techniques like Chain of Thought and Tree of Thoughts utilize task decomposition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stream steps:\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"updates\"\n",
        "):\n",
        "    print(f\"{step}\\n\\n----------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZmd-NT8aQP7",
        "outputId": "15c89723-3a0e-490a-9664-0936acf703dd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'retrieve': {'context': [Document(id='1b11d3a8-ac8f-4ffd-b46b-5b5444bd77ee', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585.0}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='7111d4a4-51bd-49c9-96a7-a72b14f5b784', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192.0}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='78ad26c4-4734-45a1-bda0-a06857e6084a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17413.0}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'), Document(id='4cc1ae5a-7b63-4a8c-92fb-b0a170b5cc1a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 19372.0}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\")]}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'generate': {'answer': 'Task decomposition is the process of breaking down a complex task into smaller, more manageable subtasks. This can be done using techniques like Chain of Thought, where a model is prompted to think step-by-step, or by generating multiple thought steps, creating a tree structure. Task decomposition can be achieved through LLM prompting, task-specific instructions, or human input.'}}\n",
            "\n",
            "----------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customizing the prompt"
      ],
      "metadata": {
        "id": "GDiC95bweG-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Above, we can load prompts (e.g., this RAG prompt) from the prompt hub. The prompt can also be easily customized.\n",
        "\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "Use three sentences maximum and keep the answer as concise as possible.\n",
        "Always say \"thanks for asking!\" at the end of the answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Helpful Answer:\n",
        "\"\"\"\n",
        "custom_rag_prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "nHxTY6SZbz7P"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part-2"
      ],
      "metadata": {
        "id": "73FiR52SiCFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In many Q&A applications we want to allow the user to have a back-and-forth conversation, meaning the application needs\n",
        "# some sort of \"memory\" of past questions and answers, and some logic for incorporating those into its current thinking.\n",
        "\n",
        "# Here we focus on adding logic for incorporating historical messages. This involves the management of a chat history."
      ],
      "metadata": {
        "id": "4_rO3hTneOkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will cover two approaches:\n",
        "\n",
        "# Chains, in which we execute at most one retrieval step.\n",
        "# Agents, in which we give an LLM discretion to execute multiple retrieval steps."
      ],
      "metadata": {
        "id": "EBWQ_qVxeNPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chains"
      ],
      "metadata": {
        "id": "mhiLFRT-jxWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In the Part-1  we represented the user input, retrieved context, and generated answer as separate keys in the state.\n",
        "# Conversational experiences can be naturally represented using a sequence of messages.\n",
        "# Addition to messages from the user and assistant retrieved documents and other artifacts can be incorporated into a message sequence via tool messages.\n",
        "\n",
        "# This motivates us to represent the state of our RAG application using a sequence of messages.\n",
        "\n",
        "# Specifically, we will have\n",
        "\n",
        "# User input as a HumanMessage;\n",
        "# Vector store query as an AIMessage with tool calls;\n",
        "# Retrieved documents as a ToolMessage;\n",
        "# Final response as a AIMessage."
      ],
      "metadata": {
        "id": "3kYZko2pjx5B"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import MessagesState, StateGraph\n",
        "\n",
        "graph_builder = StateGraph(MessagesState)"
      ],
      "metadata": {
        "id": "LXT5NFIUlQdA"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leveraging tool-calling to interact with a retrieval step has another benefit, which is that the query for the retrieval is generated by our model.\n",
        "# This is especially important in a conversational setting, where user queries may require contextualization based on the chat history.\n",
        "# As in the query analysis section of the RAG tutorial, this allows a model to rewrite user queries into more effective search queries.\n",
        "# It also provides support for direct responses that do not involve a retrieval step.\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "def retrieve(query: str):\n",
        "    \"\"\"Retrieve information related to a query.\"\"\"\n",
        "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
        "    serialized = \"\\n\\n\".join((f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")for doc in retrieved_docs)\n",
        "    return serialized, retrieved_docs"
      ],
      "metadata": {
        "id": "X5Szz19ClRTg"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our graph will consist of three nodes:\n",
        "\n",
        "# A node that fields the user input, either generating a query for the retriever or responding directly;\n",
        "# A node for the retriever tool that executes the retrieval step;\n",
        "# A node that generates the final response using the retrieved context."
      ],
      "metadata": {
        "id": "NUgKZxiRmgs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "\n",
        "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
        "def query_or_respond(state: MessagesState):\n",
        "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
        "    llm_with_tools = llm.bind_tools([retrieve])\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    # MessagesState appends messages to state instead of overwriting\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "# Step 2: Execute the retrieval.\n",
        "tools = ToolNode([retrieve])\n",
        "\n",
        "\n",
        "# Step 3: Generate a response using the retrieved content.\n",
        "def generate(state: MessagesState):\n",
        "    \"\"\"Generate answer.\"\"\"\n",
        "    # Get generated ToolMessages\n",
        "    recent_tool_messages = []\n",
        "    for message in reversed(state[\"messages\"]):\n",
        "        if message.type == \"tool\":\n",
        "            recent_tool_messages.append(message)\n",
        "        else:\n",
        "            break\n",
        "    tool_messages = recent_tool_messages[::-1]\n",
        "\n",
        "    # Format into prompt\n",
        "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
        "\n",
        "    system_message_content = (\n",
        "        \"You are an assistant for question-answering tasks. \"\n",
        "        \"Use the following pieces of retrieved context to answer \"\n",
        "        \"the question. If you don't know the answer, say that you \"\n",
        "        \"don't know. Use three sentences maximum and keep the \"\n",
        "        \"answer concise.\"\n",
        "        \"\\n\\n\"\n",
        "        f\"{docs_content}\"\n",
        "    )\n",
        "    conversation_messages = [\n",
        "        message\n",
        "        for message in state[\"messages\"]\n",
        "        if message.type in (\"human\", \"system\")\n",
        "        or (message.type == \"ai\" and not message.tool_calls)\n",
        "    ]\n",
        "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
        "\n",
        "    # Run\n",
        "    response = llm.invoke(prompt)\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "xUUEf--WmusV"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "graph_builder.add_node(query_or_respond)\n",
        "graph_builder.add_node(tools)\n",
        "graph_builder.add_node(generate)\n",
        "\n",
        "graph_builder.set_entry_point(\"query_or_respond\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"query_or_respond\",\n",
        "    tools_condition,\n",
        "    {END: END, \"tools\": \"tools\"},\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"generate\")\n",
        "graph_builder.add_edge(\"generate\", END)\n",
        "\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "pI80Qs4PnuCf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "6sfRJ31QoJIv",
        "outputId": "c2cfa7ac-4282-4c4a-878b-05dca7aa11e5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"Hello\"\n",
        "\n",
        "for step in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": input_message}]},stream_mode=\"values\",):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e04CmqUxqb8W",
        "outputId": "fde5cc36-7815-4769-ac0d-1b8b0a80e81c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hello\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"What is Task Decomposition?\"\n",
        "\n",
        "for step in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": input_message}]},stream_mode=\"values\",):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52e3Wqi4qgLe",
        "outputId": "8f053769-f05a-4e11-d3f3-04a33e18255a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is Task Decomposition?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (0f8834d6-8224-4668-9d04-65040185e16c)\n",
            " Call ID: 0f8834d6-8224-4668-9d04-65040185e16c\n",
            "  Args:\n",
            "    query: What is Task Decomposition?\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585.0}\n",
            "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
            "Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192.0}\n",
            "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Task decomposition is a method of breaking down a complex task into smaller, more manageable steps. It can be done by using simple prompts, task-specific instructions, or human input. This process is useful for enhancing model performance on complex tasks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In production, the Q&A application will usually persist the chat history into a database, and be able to read and update it appropriately.\n",
        "\n",
        "# LangGraph implements a built-in persistence layer, making it ideal for chat applications that support multiple conversational turns.\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "# Specify an ID for the thread\n",
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
      ],
      "metadata": {
        "id": "ocU1Rj5rxO0m"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"What is Task Decomposition?\"\n",
        "\n",
        "for step in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": input_message}]},stream_mode=\"values\",config=config,):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZxjT6FJxYQV",
        "outputId": "64818e40-8472-4fe9-ce1b-aa31968a0d5b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is Task Decomposition?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (0658fa67-6f85-4f7d-b50c-387c8c3335b1)\n",
            " Call ID: 0658fa67-6f85-4f7d-b50c-387c8c3335b1\n",
            "  Args:\n",
            "    query: What is Task Decomposition?\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585.0}\n",
            "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
            "Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192.0}\n",
            "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Task decomposition is the process of breaking down a complex task into smaller, more manageable steps. This can be achieved through methods such as chain of thought prompting, where the model is instructed to \"think step by step\". It can also be done by using task-specific instructions or human input.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"Can you look up some common ways of doing it?\"\n",
        "\n",
        "for step in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": input_message}]},stream_mode=\"values\",config=config,):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rIjTWlxxsct",
        "outputId": "2eb8ea08-1c00-4c7e-b26e-804545a730bd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Can you look up some common ways of doing it?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (f4e7a5cf-ba47-4c84-8451-5a8d6871e399)\n",
            " Call ID: f4e7a5cf-ba47-4c84-8451-5a8d6871e399\n",
            "  Args:\n",
            "    query: common ways to do task decomposition\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192.0}\n",
            "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585.0}\n",
            "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
            "Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Yes, common ways of doing task decomposition include using LLMs with simple prompts, task-specific instructions, and human input. For example, an LLM can be prompted with \"Steps for XYZ.\\n1.\" or \"What are the subgoals for achieving XYZ?\". Task-specific instructions can include prompts like \"Write a story outline\" for writing a novel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents"
      ],
      "metadata": {
        "id": "ZkUO_UJQyFzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agents leverage the reasoning capabilities of LLMs to make decisions during execution.\n",
        "# Using agents allows you to offload additional discretion over the retrieval process.\n",
        "# Although their behavior is less predictable than the above \"chain\", they are able to execute multiple retrieval steps in service of a query,\n",
        "# or iterate on a single search.\n",
        "\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)"
      ],
      "metadata": {
        "id": "8ilu_qqdx2pE"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Image(agent_executor.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "0zgJbAmuyxV1",
        "outputId": "e164f9e6-779c-4466-c511-ab198935d687"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"def234\"}}\n",
        "\n",
        "input_message = (\n",
        "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
        "    \"Once you get the answer, look up common extensions of that method.\"\n",
        ")\n",
        "\n",
        "for event in agent_executor.stream({\"messages\": [{\"role\": \"user\", \"content\": input_message}]},stream_mode=\"values\",config=config,):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vTsxi7xyzIM",
        "outputId": "5f951071-6f59-4d52-b79f-e64d78fb2020"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is the standard method for Task Decomposition?\n",
            "\n",
            "Once you get the answer, look up common extensions of that method.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (bde3baa2-4e08-4714-8836-2c0f7796a59b)\n",
            " Call ID: bde3baa2-4e08-4714-8836-2c0f7796a59b\n",
            "  Args:\n",
            "    query: standard method for Task Decomposition\n",
            "  retrieve (30e74f07-adfc-4ba3-af55-e25969d51e3f)\n",
            " Call ID: 30e74f07-adfc-4ba3-af55-e25969d51e3f\n",
            "  Args:\n",
            "    query: common extensions of Task Decomposition\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192.0}\n",
            "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "\n",
            "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585.0}\n",
            "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
            "Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The standard method for task decomposition is Chain of Thought (CoT) prompting, where the model is instructed to \"think step by step\" to break down complex tasks into smaller, more manageable steps.\n",
            "\n",
            "Common extensions of this method include:\n",
            "\n",
            "*   **Tree of Thoughts (ToT):** This extends CoT by exploring multiple reasoning possibilities at each step, creating a tree structure of thoughts. The search process can be breadth-first or depth-first, with each state evaluated by a classifier or majority vote.\n"
          ]
        }
      ]
    }
  ]
}