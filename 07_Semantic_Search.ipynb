{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBEpscEBV82j9tvoa23U6o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahsanrazi/LangChain/blob/main/07_Semantic_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY').strip()"
      ],
      "metadata": {
        "id": "1Wvt6ATM067a"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-community pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6GFCMLH1a14",
        "outputId": "eeedb147-db29-4fba-ddde-008d01db9333"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/2.5 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.7/298.7 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Searh Engine"
      ],
      "metadata": {
        "id": "0RveFtAHzkah"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yCQWmu6wzQC6"
      },
      "outputs": [],
      "source": [
        "# This tutorial will familiarize us with LangChain's document loader, embedding, and vector store abstractions.\n",
        "# They are important for applications that fetch data to be reasoned over as part of model inference as in the case of RAG.\n",
        "\n",
        "# We will build a search engine over a PDF document. This will allow us to retrieve passages in the PDF that are similar to an input query."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Documents and Document Loaders"
      ],
      "metadata": {
        "id": "AtloDOk504U_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain implements a Document abstraction, which is intended to represent a unit of text and associated metadata.\n",
        "\n",
        "# It has three attributes:\n",
        "# page_content: a string representing the content\n",
        "# metadata: a dict containing arbitrary metadata\n",
        "# id: (optional) a string identifier for the document.\n",
        "\n",
        "# The metadata attribute can capture information about the source of the document, its relationship to other documents, and other information.\n",
        "# An individual Document object often represents a chunk of a larger document."
      ],
      "metadata": {
        "id": "WdzqIgRy0Z_C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can generate sample documents when desired.\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "rRTFZo5i163Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading documents"
      ],
      "metadata": {
        "id": "v_zrCjit2XKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain ecosystem implements document loaders that integrate with hundreds of common sources."
      ],
      "metadata": {
        "id": "SgWcH1W62RXw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load a PDF into a sequence of Document objects.\n",
        "# Use PyPDFLoader, which is fairly lightweight.\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "file_path = \"/content/WBT.pdf\"\n",
        "\n",
        "loader = PyPDFLoader(file_path)\n",
        "\n",
        "docs = loader.load()\n",
        "\n",
        "print(len(docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me468gWv2UjQ",
        "outputId": "25f49b94-7907-478a-a72e-3132cf72f9e0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyPDFLoader loads one Document object per PDF page. For each, we can easily access:\n",
        "\n",
        "# The string content of the page;\n",
        "# Metadata containing the file name and page number.\n",
        "\n",
        "print(f\"{docs[0].page_content[:200]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Sw7Euqf4ZRo",
        "outputId": "33e1f7a3-23aa-4810-d095-0f9dbd320ebe"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Knowledge Base: We Build Trades \n",
            "About \n",
            "We Build Trades is a UK-based digital marketing and software agency founded in 2017 by Daniel Brown. \n",
            "It specializes in comprehensive marketing solutions for tr\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97yJoEgf4mIn",
        "outputId": "1f429a82-256a-4472-b8b0-abb5434d8113"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'source': '/content/WBT.pdf', 'page': 0, 'page_label': '1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting"
      ],
      "metadata": {
        "id": "j6wh6rez4p1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For both information retrieval and downstream question-answering purposes, a page may be too coarse a representation.\n",
        "# Our goal in the end will be to retrieve Document objects that answer an input query, and further splitting our PDF will help ensure that\n",
        "# the meanings of relevant portions of the document are not \"washed out\" by surrounding text.\n",
        "\n",
        "# We can use text splitters for this purpose.\n",
        "# We use the RecursiveCharacterTextSplitter, which will recursively split the document using common separators like new lines\n",
        "# until each chunk is the appropriate size. This is the recommended text splitter for generic text use cases.\n",
        "\n",
        "# We set add_start_index=True so that the character index where each split Document starts\n",
        "# within the initial Document is preserved as metadata attribute “start_index”.\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=750, chunk_overlap=300, add_start_index=True)\n",
        "\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "len(all_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hziHZyEF4nDn",
        "outputId": "a088f0c2-611d-49db-954f-d6ba643d3c22"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings"
      ],
      "metadata": {
        "id": "nFqNRd0a7lKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-google-genai"
      ],
      "metadata": {
        "id": "V-onq48z8gZV"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector search is a common way to store and search over unstructured data (such as unstructured text).\n",
        "# The idea is to store numeric vectors that are associated with the text.\n",
        "# We can embed it as a vector of the same dimension and use vector similarity metrics (such as cosine similarity) to identify related text."
      ],
      "metadata": {
        "id": "oORdRsEI7iTg"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# os.environ['GOOGLE_API_KEY'] = gemini_api_key"
      ],
      "metadata": {
        "id": "bws3o_nWCuAd"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key = gemini_api_key)"
      ],
      "metadata": {
        "id": "TJcd57Dv8cdV"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_1 = embeddings.embed_query(all_splits[0].page_content)\n",
        "vector_2 = embeddings.embed_query(all_splits[1].page_content)"
      ],
      "metadata": {
        "id": "VzVZjvu5_Q2k"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vector_1[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afIUEhOs_Ryv",
        "outputId": "73e4d921-2c22-4fb6-e101-c4f2ca2a9b59"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.042216330766677856, -0.06837313622236252, -0.02941972203552723, -0.01358675118535757, 0.06945652514696121, 0.0012776809744536877, 0.052310261875391006, 0.003017732407897711, 0.03554920852184296, 0.029503092169761658]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vector_2[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApY46LREDUnL",
        "outputId": "7fc764a6-b356-4ff7-e11f-7a8c10c2fa32"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06741836667060852, -0.053920891135931015, -0.03039383701980114, -0.01967283897101879, 0.033709362149238586, 0.005014019086956978, 0.024784499779343605, -0.024772273376584053, 0.03712800145149231, 0.03918985277414322]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector stores"
      ],
      "metadata": {
        "id": "r_ejHh4TET1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-pinecone"
      ],
      "metadata": {
        "id": "HwV8JmjHFJxG"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain VectorStore objects contain methods for adding text and Document objects to the store, and querying them using various similarity metrics.\n",
        "# They are often initialized with embedding models, which determine how text data is translated to numeric vectors."
      ],
      "metadata": {
        "id": "MZsMwbmuEPsT"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone\n",
        "\n",
        "index_name = \"langchain\"\n",
        "namespace = \"Example\"\n",
        "\n",
        "pc = Pinecone(api_key= userdata.get('PINECONE_API'))\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "vector_store = PineconeVectorStore(embedding=embeddings, index=index, namespace=namespace)"
      ],
      "metadata": {
        "id": "BBhTcxigEu_M"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Having instantiated our vector store, we can now index the documents.\n",
        "\n",
        "ids = vector_store.add_documents(documents=all_splits)"
      ],
      "metadata": {
        "id": "G8oGOJ4sHaez"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usage"
      ],
      "metadata": {
        "id": "YhIabYtXJwHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embeddings typically represent text as a \"dense\" vector such that texts with similar meanings are geometrically close.\n",
        "# This lets us retrieve relevant information just by passing in a question, without knowledge of any specific key-terms used in the document.\n",
        "\n",
        "# Return documents based on similarity to a string query\n",
        "results = vector_store.similarity_search(\"Who is the founder of We Build Trade\")\n",
        "\n",
        "print(results[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqjf342dH1aq",
        "outputId": "3d56f320-5c23-45d5-8843-e511f1ee0870"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Core Values \n",
            "We Build Trades operates with the following principles: \n",
            "1. Client Obsession \n",
            "o Always prioritizing what is best for clients. \n",
            "2. Full Transparency \n",
            "o Maintaining honesty and openness in all dealings. \n",
            "3. Long-Term Thinking \n",
            "o Emphasizing sustainable growth over short-term gains. \n",
            "4. Relentless Ambition \n",
            "o Continuously striving for excellence and improvement. \n",
            " \n",
            "Founder: Daniel Brown \n",
            "• Role: Founder and CEO of We Build Trades. \n",
            "• Career Start: Former senior marketing consultant. \n",
            "• Journey: Founded We Build Trades in 2017 with limited resources but strong mentorship and a \n",
            "passion for learning. \n",
            "• Achievements: Under his leadership, the agency has served over 60 clients and expanded \n",
            "internationally. \n",
            " \n",
            "Key Differentiators' metadata={'page': 1.0, 'page_label': '2', 'source': '/content/WBT.pdf', 'start_index': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Async query:\n",
        "\n",
        "results = await vector_store.asimilarity_search(\"Who is the founder of We Build Trade\")\n",
        "\n",
        "print(results[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO4kJMgLKhlK",
        "outputId": "3cc2d287-b8bf-4159-80b0-15e91c1bb80f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Core Values \n",
            "We Build Trades operates with the following principles: \n",
            "1. Client Obsession \n",
            "o Always prioritizing what is best for clients. \n",
            "2. Full Transparency \n",
            "o Maintaining honesty and openness in all dealings. \n",
            "3. Long-Term Thinking \n",
            "o Emphasizing sustainable growth over short-term gains. \n",
            "4. Relentless Ambition \n",
            "o Continuously striving for excellence and improvement. \n",
            " \n",
            "Founder: Daniel Brown \n",
            "• Role: Founder and CEO of We Build Trades. \n",
            "• Career Start: Former senior marketing consultant. \n",
            "• Journey: Founded We Build Trades in 2017 with limited resources but strong mentorship and a \n",
            "passion for learning. \n",
            "• Achievements: Under his leadership, the agency has served over 60 clients and expanded \n",
            "internationally. \n",
            " \n",
            "Key Differentiators' metadata={'page': 1.0, 'page_label': '2', 'source': '/content/WBT.pdf', 'start_index': 0.0}\n"
          ]
        }
      ]
    }
  ]
}